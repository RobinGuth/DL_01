\documentclass[a4paper]{article}

\usepackage{listings}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage[hidelinks]{hyperref}

%opening
\title{Deep Reinforcement Learning Beginners Tutorial \\Documentation}
\author{Julian Bernhart, Robin Guth}

\begin{document}
	
	\maketitle
	\tableofcontents
	
	\section{Introduction}
	\textit{Deep Reinforcement Learning} is a huge step towards the creation of an universal artificial intelligence\footnote{can be used for multiple problems without notable changes}.
	In 2013 a company, owned by Google, called ''Deep Mind'', was able to create an astonishing implementation of RL\footnote{Reinforcement Learning}, which was capable to play a range of retro games of the console ''Atari 2600''.
	In many cases, the AI\footnote{Artificial Intelligence} was not only able to play the games successfully, but also exceeded human performances significantly \cite{atari}.
	After these impressive results, it is definitely worth to take a closer look at \textit{reinforcement learning}.\\	  
	Playing games is fun, but \textit{reinforcement learning} has more to offer, as discussed in \cite{usecasesRL}.
	Apart from playing video games, there are many use cases in fields like robotics, traffic control or even personalized advertisement.
	Apart from the Atari paper \cite{atari}, multiple papers have been written about RL.
	Some noteworthy examples are the creation of an RL algorithm, which recommends personalized news \cite{drn} or a survey about different applications for RL in robotics \cite{roboticsRL}. While supervised and unsupervised learning are already widely used in production, \textit{reinforcement learning} is still in development and further research is needed.
	As an interesting topic with many application possibilities, there is a demand for tutorials and hands-on guides for beginners, especially students.
	Beginners often struggle to find a good starting point into the world of AI and specifically RL.
	Many existing tutorials are written for more advanced users, who already have a deeper understanding of machine learning.\\
	For this reason, the \textit{''Deep Reinforcement Learning Beginners Tutorial''} was created, as an effort to create an easy to understand, hands-on guide to learn RL without needing extensive knowledge about \textit{machine learning}.
	After completing the tutorial, the reader will be familiar with the basics of RL and be able to create its own implementation based on the examples given.\\
	This document serves as a documentation of the making and thought-process of the authors, as well as a presentation of the result and a critical reflection of the work.
	First, the basic contents of the tutorial will be explained, to give the reader a short overview about the topic of RL.
	Then, the initial targets will be outlined as well as the methods and materials, that were used in the making.
	Finally, all results will be presented and evaluated against the initial targets. 
	This document will be concluded by the discussion of possible improvements and expansions of the final product.
		 
	%Section: Content//Deep Reinforcement Learning
	\input{deepreinforcementlearning.tex}

	\section{Initial Targets}
		As the reader is now familiar with the topic of RL, in this section, the initial targets will be discussed. Later on, these targets are critically compared to the results. Some of the presented targets may overlap.
		
		\begin{description}
			\item[Beginner-Friendly] 	The main goal in the creation of this tutorial is to create an easy understandable, hands-on beginners guide to RL.
			This means that there need to be extra steps to reach this target like:
			\begin{itemize}
				\item extensive, comprehensive explanations
				\item explanations for new terms
				\item accompanying images/visualizations
				\item easy language
				\item explained code examples
				\item simple exercises with solutions
				\item inviting environment 
				\item no big obstacles without support
				\item easy to set up
				\item etc.
			\end{itemize}
		
			\item[Relevant Knowledge] After the completion of the tutorial, the user should be able to proceed with other tutorials or sources, without needing to start over again. The knowledge presented should contain necessary and useful basics of RL.
			
			\item[Easy Code] As the programming language \textit{Python} dominates fields like \textit{data science} or \textit{machine learning}, it was made with the intention of creating a very simple programming language and many libraries being written in \textit{Python}, this seems an excellent choice for this tutorial.\\ 
			
			\item[Combination of text and code] Many tutorials in existence require the installation of additional software, like compilers for the programming language. This separates the code from the theory and explanations. For this reason, the code and text should be in the same document, so that a reader can instantly run code while reading the explanations. 
			
			\item[Performance] An important point to consider is the required computing power to train an agent. As many thousands to millions of steps are needed, this is more than most personal computers can handle in a decent amount of time.  
			For this reason, the tutorial should be based on the usage of a cloud service to execute code. 
			This delivers enough computational power to train an agent in a short period of time, as well as separating the execution environment from the users personal hardware, which removes the need to install software on the users pc.
		\end{description}

	\section{Methods and Materials}
		In this section, the methods and materials used in the creation of the notebooks are presented, as well as the thought process of the authors. Problems, which occurred are discussed and some solutions are offered.
		
		
	keras etc
	jupyter lab
	We-form
	open ai gym: 
		As we discussed before, Reinforcement Learning can be used to solve a range of different problems. Developing Machine Learning algorithms is often not easy to understand nor comprehensible especially for beginners. Furthermore, it is important to be able to compare the performance of different iterations of our algorithm, to be able to improve it.
		
		So bascially we need an environment, that we can use to test and train our RL agent, which fulfills the following requirements:
		
		repeatable test/training epochs
		finite set of inputs
		finite set of actions
		easy state representation
		easy to control agent
		deliver a score for a given state
		
		In practice, not all of these points will be fulfilled, but as this is a beginners guide, we will start with a simple environment. Luckily, many video games can be used as quite good environments for machine learning purposes. Many implementations of RL are tested with games as Benchmark and there are some good reasons for this. Developing a whole test environment would be labour intensive and would require dedicated work towards a useable simulator. Using an existing game is also easier to compare to human performance and therefore the evaluation of different algorithms is easier. Another important point is the size of possible inputs and actions. The AI replaces the human player. Depending on the game, the input for our agent is an image, like a human player would see it. The set of actions is a combination of different buttons, which can be pressed on a controller. Finally, games are fun and most people can relate to them. It is also easier to understand what we want to accomplish, because we can transfer aspects from our human play style to the behaviour of an AI. 

		\subsection{The OpenAi Gym Framework}
		OpenAi Gym is the Framework that is used to provide a game environment. Developing \textit{machine learning} algorithms is often neither easy to understand nor comprehensible especially for beginners. As most people are familiar with videogames, a game was chosen as a simple and completely observable environment. OpenAi Gym is an open source framework, which delivers a range of different game environment. It provides all environmental data an RL agent needs and using an existing game makes it also easier to compare the agent to human performance and also other agents and therefore the evaluation of different algorithms is easier.
		Another advantage is, that a developer does not need to build a dedicated testing environment and save time.
		
		\subsection{The Exercises}
		The exercises are a comparatively small part of the notebooks. The main goal is to explain \textit{deep reinforcement learning}. The notebooks were designed to be easily understandable with a good connection between theory and implementation. All code passages are explained in detail, so that the project can be comprehended in its entirety. The goal of the exercises is to build and understand a basic structure for a RL agent. The individual tasks are located at the points in the code where the agent can be further optimized and customized to create an entry point into a project.
	
	\section{Results}
	critic/ expensions:
		using a framework
		policy learning / value learning -> both variants as cartpole agent
		policy gradient
	
	Alles fuer Verwendung in Cloud
	
	Einstiegshilfe: 
		- alles erklaert
		- Einfacheres Codebeispiel
		- Grundgeruest (Code) und Grundlagenwissen fuer weitere Projekte
	
	zwei notebooks:
		1. Theorie: 
			- Agenten erlaeutert
			- RL allgemein und am Bsp Spiel	
			- Deep Learning Aspect
			- Q-Learning mit Herleitung Formeln
			- Modelliermoeglichkeiten fuer DQN
			- Outlook
		2. Beispiel Code:
			- Theorie umgesetzt
			- Framework vorgestellt
			- anhand von Spiel -> Beispiel
			- rendern 
			- alles genau erklaert -> Einsteigerfreundlich
			- DQN Agent erstellen, trainieren
			- Uebungen
			- Outlook, Verbesserungen etc.
			
	Installationsguide
	
	Weiterfuehrende Quellen
	
	\bibliography{bib} 
	\bibliographystyle{ieeetr}
\end{document}
